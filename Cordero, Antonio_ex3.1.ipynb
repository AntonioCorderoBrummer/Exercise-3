{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\acord\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\acord\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\acord\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\acord\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\acord\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\acord\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\acord\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\acord\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acord\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acord\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\acord\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "# INSTALL REQUIRED LIBRARIES (if needed)\n",
    "# Install necessary libraries for machine learning, NLP, and deep learning\n",
    "!pip install torch torchvision torchaudio scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras filas del dataset:\n",
      "   NewsID   Category               SubCategory  \\\n",
      "0  N88753  lifestyle           lifestyleroyals   \n",
      "1  N45436       news  newsscienceandtechnology   \n",
      "2  N23144     health                weightloss   \n",
      "3  N86255     health                   medical   \n",
      "4  N93187       news                 newsworld   \n",
      "\n",
      "                                               Title  \\\n",
      "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
      "1    Walmart Slashes Prices on Last-Generation iPads   \n",
      "2                      50 Worst Habits For Belly Fat   \n",
      "3  Dispose of unwanted prescription drugs during ...   \n",
      "4  The Cost of Trump's Aid Freeze in the Trenches...   \n",
      "\n",
      "                                            Abstract  \\\n",
      "0  Shop the notebooks, jackets, and more that the...   \n",
      "1  Apple's new iPad releases bring big deals on l...   \n",
      "2  These seemingly harmless habits are holding yo...   \n",
      "3                                                NaN   \n",
      "4  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
      "\n",
      "                                             URL  \\\n",
      "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
      "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
      "2  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
      "3  https://assets.msn.com/labs/mind/AAISxPN.html   \n",
      "4  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
      "\n",
      "                                       TitleEntities  \\\n",
      "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
      "3  [{\"Label\": \"Drug Enforcement Administration\", ...   \n",
      "4                                                 []   \n",
      "\n",
      "                                    AbstractEntities  \n",
      "0                                                 []  \n",
      "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...  \n",
      "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
      "3                                                 []  \n",
      "4  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
      "\n",
      "Categorías disponibles:\n",
      "['lifestyle' 'news' 'health' 'sports' 'weather' 'entertainment'\n",
      " 'foodanddrink' 'autos' 'travel' 'video' 'finance' 'tv' 'movies' 'music'\n",
      " 'kids' 'middleeast' 'games' 'northamerica']\n",
      "\n",
      "Ejemplo de datos utilizados para el entrenamiento:\n",
      "                                                   Title Category\n",
      "21815     Pareja Emerges as Favorite to Replace O'Connor   sports\n",
      "64515                Houston Texans Sack Tracker: Week 8   sports\n",
      "41270        Essence Healthcare - Primary Care Phyisican   health\n",
      "56800  Sto-Rox School District Banning Students From ...     news\n",
      "40822  Submarine that disappeared mysteriously in Wor...   travel\n"
     ]
    }
   ],
   "source": [
    "# IMPORT LIBRARIES\n",
    "import pandas as pd # For handling tabular data (loading, filtering, etc.)\n",
    "# From scikit-learn:\n",
    "from sklearn.model_selection import train_test_split # To split dataset into training and testing subsets\n",
    "from sklearn.preprocessing import LabelEncoder # To convert text labels into numeric classes\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # To transform text into TF-IDF vectors\n",
    "# From PyTorch:\n",
    "import torch # Core library for deep learning\n",
    "from torch.utils.data import DataLoader, TensorDataset # For batching and organizing data for training\n",
    "\n",
    "# LOAD AND EXPLORE THE DATASET\n",
    "file_path = 'news.tsv' # Define the path to the dataset file (TSV = Tab-Separated Values)\n",
    "\n",
    "df_news = pd.read_csv(file_path, sep='\\t', header=None) # Load the TSV file into a pandas DataFrame, with no header row specified\n",
    "# Assign column names based on dataset documentation \n",
    "df_news.columns = [\n",
    "    'NewsID', 'Category', 'SubCategory', 'Title', 'Abstract', \n",
    "    'URL', 'TitleEntities', 'AbstractEntities'\n",
    "]\n",
    "# Display the first few rows of the dataset to inspect structure and content\n",
    "print(\"Primeras filas del dataset:\")\n",
    "print(df_news.head())\n",
    "\n",
    "# SELECT RELEVANT COLUMNS FOR THE TASK\n",
    "# Keep only the 'Title' and 'Category' columns for classification\n",
    "# Drop rows with missing values (NaN)\n",
    "df = df_news[['Title', 'Category']].dropna()\n",
    "\n",
    "# Display all unique categories in the dataset\n",
    "print(\"\\nCategorías disponibles:\")\n",
    "print(df['Category'].unique())\n",
    "\n",
    "# Show a random sample of 5 entries for inspection\n",
    "print(\"\\nEjemplo de datos utilizados para el entrenamiento:\")\n",
    "print(df.sample(5))\n",
    "\n",
    "# ENCODE CATEGORIES INTO NUMERIC LABELS\n",
    "\n",
    "# Initialize the label encoder\n",
    "le = LabelEncoder()\n",
    "df['Category'] = le.fit_transform(df['Category']) # Convert text categories to integer labels and update the 'Category' column\n",
    "\n",
    "# SPLIT DATA INTO TRAINING AND TESTING SETS\n",
    "# Use 80% of the data for training and 20% for testing\n",
    "# X = news titles (input), y = encoded category labels (target)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Title'], df['Category'], test_size=0.2, random_state=42)\n",
    "\n",
    "# TRANSFORM TEXT INTO TF-IDF FEATURE VECTORS\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000) # Initialize TF-IDF vectorizer (max 5000 most frequent words)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train).toarray() # Fit the vectorizer on the training text and convert it to dense vectors\n",
    "X_test_tfidf = vectorizer.transform(X_test).toarray() # Transform the test text using the already-fitted vectorizer\n",
    "\n",
    "# CONVERT DATA INTO PYTORCH TENSORS\n",
    "# Convert TF-IDF feature matrices and labels into PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_tfidf, dtype=torch.float32) \n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_tfidf, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# CREATE DATASETS AND DATALOADERS\n",
    "# Combine features and labels into PyTorch TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "# Create DataLoaders to feed data in batches during training\n",
    "# Shuffle training data to improve learning\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "# Test loader does not shuffle to preserve data order\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT MODULES FOR BUILDING NEURAL NETWORKS\n",
    "import torch.nn as nn # Provides base classes for building neural network layers\n",
    "import torch.nn.functional as F # Provides common activation functions like ReLU, etc.\n",
    "\n",
    "# DEFINE A SIMPLE FEEDFORWARD NEURAL NETWORK\n",
    "# This class defines the architecture of the neural network for text classification\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        # First fully connected layer:\n",
    "        # Input: TF-IDF vector of length 'input_dim'\n",
    "        # Output: a hidden representation of size 'hidden_dim'\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "         # Second fully connected layer:\n",
    "        # Input: hidden representation\n",
    "        # Output: scores for each of the 'output_dim' classes\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    # Define the forward pass through the network\n",
    "    def forward(self, x):\n",
    "        # Apply ReLU activation to the output of the first layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Output raw scores (logits) from the second layer\n",
    "        # (CrossEntropyLoss will handle softmax internally)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# SET MODEL HYPERPARAMETERS\n",
    "input_dim = X_train_tfidf.shape[1] # Number of input features = number of TF-IDF terms (columns)\n",
    "hidden_dim = 100 # Number of hidden units in the middle layer (can be tuned)\n",
    "output_dim = len(le.classes_) # Number of output classes (equal to the number of unique categories)\n",
    "\n",
    "# INSTANTIATE THE MODEL\n",
    "model = TextClassifier(input_dim, hidden_dim, output_dim) # Create an instance of the neural network with the specified dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.2121\n",
      "Epoch 2/10, Loss: 0.8165\n",
      "Epoch 3/10, Loss: 0.7180\n",
      "Epoch 4/10, Loss: 0.6536\n",
      "Epoch 5/10, Loss: 0.6004\n",
      "Epoch 6/10, Loss: 0.5490\n",
      "Epoch 7/10, Loss: 0.4987\n",
      "Epoch 8/10, Loss: 0.4498\n",
      "Epoch 9/10, Loss: 0.4008\n",
      "Epoch 10/10, Loss: 0.3525\n"
     ]
    }
   ],
   "source": [
    "# IMPORT OPTIMIZER MODULE\n",
    "import torch.optim as optim # Contains optimization algorithms like SGD, Adam, etc.\n",
    "\n",
    "# DEFINE LOSS FUNCTION AND OPTIMIZER\n",
    "# CrossEntropyLoss is commonly used for multi-class classification problems.\n",
    "# It combines LogSoftmax and Negative Log Likelihood Loss in one function.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Adam optimizer is used to update the model weights based on the gradients.\n",
    "# It is an adaptive optimizer that often works well out-of-the-box.\n",
    "# lr=0.001 sets the learning rate (step size for weight updates).\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# DEFINE THE TRAINING FUNCTION\n",
    "# This function trains the model over multiple epochs using the provided DataLoader.\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=50):\n",
    "    # Set the model to training mode (activates dropout, etc. if used)\n",
    "    model.train()\n",
    "    # Loop through the specified number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0 # Accumulate total loss for reporting\n",
    "        # Loop through each mini-batch in the training DataLoader\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad() # Reset gradients to zero\n",
    "            outputs = model(inputs) # Forward pass: compute predictions\n",
    "            loss = criterion(outputs, labels) # Compute the loss\n",
    "            loss.backward() # Backward pass: compute gradients\n",
    "            optimizer.step() # Update model parameters\n",
    "            total_loss += loss.item() # Accumulate loss for this batch\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}') # Print average loss for the current epoch\n",
    "\n",
    "# TRAIN THE MODEL\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=10) # Call the training function for 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy en test: 0.6854\n",
      "Reporte de clasificación:\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        autos       0.53      0.55      0.54       612\n",
      "entertainment       0.43      0.34      0.38       153\n",
      "      finance       0.53      0.48      0.51      1227\n",
      " foodanddrink       0.62      0.64      0.63       881\n",
      "        games       0.00      0.00      0.00         0\n",
      "       health       0.60      0.56      0.58       608\n",
      "         kids       0.00      0.00      0.00        15\n",
      "    lifestyle       0.46      0.43      0.45       897\n",
      "   middleeast       0.00      0.00      0.00         0\n",
      "       movies       0.59      0.48      0.53       179\n",
      "        music       0.57      0.48      0.52       249\n",
      "         news       0.68      0.72      0.70      6140\n",
      " northamerica       0.00      0.00      0.00         0\n",
      "       sports       0.89      0.90      0.90      6368\n",
      "       travel       0.41      0.39      0.40       958\n",
      "           tv       0.31      0.34      0.32       243\n",
      "        video       0.32      0.27      0.29       928\n",
      "      weather       0.65      0.67      0.66       848\n",
      "\n",
      "    micro avg       0.69      0.69      0.69     20306\n",
      "    macro avg       0.42      0.40      0.41     20306\n",
      " weighted avg       0.68      0.69      0.68     20306\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acord\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acord\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acord\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acord\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acord\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acord\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acord\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acord\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\acord\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# IMPORT METRICS FOR MODEL EVALUATION\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# accuracy_score: computes the percentage of correctly predicted labels\n",
    "# classification_report: provides precision, recall, f1-score per class\n",
    "\n",
    "# DEFINE MODEL EVALUATION FUNCTION\n",
    "def evaluate_model(model, test_loader): # This function evaluates the trained model on the test dataset\n",
    "    model.eval() # Set the model to evaluation mode (disables dropout, etc.)\n",
    "    all_preds = [] # To store all predicted labels\n",
    "    all_labels = [] # To store all true labels\n",
    "    # Disable gradient calculations for faster and more memory-efficient inference\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs) # Forward pass to get predictions\n",
    "            _, preds = torch.max(outputs, 1) # Select class with highest predicted score\n",
    "            all_preds.extend(preds.numpy()) # Store predictions\n",
    "            all_labels.extend(labels.numpy()) # Store true labels\n",
    "    \n",
    "    # Generate a detailed classification report:\n",
    "    # Includes precision, recall, f1-score and support for each class\n",
    "    report = classification_report(\n",
    "        all_labels,\n",
    "        all_preds,\n",
    "        labels=list(range(len(le.classes_))), # Specify the range of class indices   \n",
    "        target_names=le.classes_              # Use original class names for readability\n",
    "    )\n",
    "    # Calculate overall accuracy: percentage of correct predictions\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return accuracy, report # Return both metrics for further use\n",
    "\n",
    "# EVALUATE THE MODEL ON TEST DATA\n",
    "# Call the evaluation function using the test data loader\n",
    "accuracy, report = evaluate_model(model, test_loader)\n",
    "# Print overall test accuracy\n",
    "print(f'\\nAccuracy en test: {accuracy:.4f}')\n",
    "# Print detailed classification report per class\n",
    "print('Reporte de clasificación:\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto de ejemplo: \"Doctors go strike\"\n",
      "Categoría predicha: \"health\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# FUNCTION TO PREDICT CATEGORY FOR NEW TEXT\n",
    "\n",
    "# This function takes a raw news title and returns its predicted category.\n",
    "# Inputs:\n",
    "# - text: a string (news title)\n",
    "# - model: the trained classification model\n",
    "# - vectorizer: the fitted TF-IDF vectorizer\n",
    "# - label_encoder: the LabelEncoder used to encode original category labels\n",
    "def predict_category(text, model, vectorizer, label_encoder):\n",
    "    model.eval() # Set the model to evaluation mode (disables dropout, etc.)\n",
    "    text_tfidf = vectorizer.transform([text]).toarray() # Convert the input text into a TF-IDF vector using the same vectorizer as during training\n",
    "    text_tensor = torch.tensor(text_tfidf, dtype=torch.float32) # Convert the TF-IDF vector into a PyTorch tensor\n",
    "    # Turn off gradient tracking for inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(text_tensor) # Get model predictions (logits)\n",
    "        _, preds = torch.max(outputs, 1) # Select the index of the class with the highest predicted score\n",
    "    category = label_encoder.inverse_transform(preds.numpy()) # Convert the predicted class index back into the original category label\n",
    "    return category[0] # Return the predicted label as a string\n",
    "\n",
    "# EXAMPLE: PREDICT CATEGORY FOR A SAMPLE NEWS TITLE\n",
    "# Example input: a new news headline in Spanish \n",
    "new_text = \"Doctors go strike\"\n",
    "predicted_category = predict_category(new_text, model, vectorizer, le) # Predict the category of the example text using the trained model\n",
    "\n",
    "# Print the input text and its predicted category\n",
    "print(f'\\nTexto de ejemplo: \"{new_text}\"')\n",
    "print(f'Categoría predicha: \"{predicted_category}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
